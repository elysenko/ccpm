# Research Plan: LLM Prompt Engineering Best Practices

## Subquestions and Query Strategy

### SQ1: Structure & Formatting
**Goal**: Evidence for XML tags, markdown, section organization

**Planned Queries**:
1. "Anthropic Claude XML tags prompt structure 2024 2025"
2. "prompt engineering formatting best practices Claude"
3. "Claude documentation prompt structure guidelines"

**Source Classes**:
- Anthropic official docs (required)
- Academic papers on formatting
- Practitioner guides

---

### SQ2: Reasoning Enhancement
**Goal**: Chain-of-thought and extended thinking evidence

**Planned Queries**:
1. "Claude extended thinking reasoning performance"
2. "chain of thought prompting effectiveness study"
3. "Anthropic thinking tags step by step reasoning"

**Source Classes**:
- Anthropic docs on extended thinking
- Academic CoT papers
- Benchmark comparisons

---

### SQ3: System Prompt Architecture
**Goal**: Effective system prompt design patterns

**Planned Queries**:
1. "Claude system prompt design best practices"
2. "LLM system prompt architecture guidelines"
3. "persona constraints system message design"

**Source Classes**:
- Anthropic docs
- Enterprise deployment guides
- Practitioner experience

---

### SQ4: Few-Shot vs Zero-Shot
**Goal**: When examples help vs hurt

**Planned Queries**:
1. "few-shot vs zero-shot prompting when to use"
2. "in-context learning examples effectiveness"
3. "Claude few-shot examples guidance"

**Source Classes**:
- Academic comparative studies
- Anthropic recommendations
- Task-specific guidance

---

### SQ5: Security & Injection Prevention
**Goal**: Mitigation techniques and their limits

**Planned Queries**:
1. "prompt injection prevention techniques 2024 2025"
2. "Claude prompt injection security mitigation"
3. "LLM prompt security best practices"

**Source Classes**:
- Security research papers
- Anthropic security guidance
- Red team findings

---

### SQ6: Claude-Specific Optimizations
**Goal**: Unique Claude features and behaviors

**Planned Queries**:
1. "Claude model specific prompting techniques"
2. "Anthropic Claude prompt optimization guide"
3. "Claude 3.5 3 Opus Sonnet prompting differences"

**Source Classes**:
- Anthropic documentation
- Model comparison guides
- Version-specific guidance

---

### SQ7: Safety & Alignment
**Goal**: Constitutional AI and safety interactions

**Planned Queries**:
1. "Constitutional AI prompting implications"
2. "Claude safety guardrails system prompts"
3. "Anthropic harmless helpful honest prompting"

**Source Classes**:
- Anthropic safety documentation
- Academic alignment papers
- Safety evaluation frameworks

---

## Source Priority Hierarchy

1. **Tier A (Required)**: docs.anthropic.com, Anthropic research papers
2. **Tier B (Preferred)**: Academic papers (arxiv), Anthropic blog
3. **Tier C (Supporting)**: Reputable tech publications, practitioner guides
4. **Tier D (Context only)**: Blog posts, community discussions

## Stop Rules

1. **Coverage**: All 7 subquestions have â‰¥3 quality sources
2. **Saturation**: Last 3 queries yield <10% new information
3. **Confidence**: All hypotheses have sufficient evidence to update
4. **Budget**: Max 30 searches, 30 fetches

## Initial Query Priority

Execute in this order (parallel where possible):

**Round 1** (Foundation - Anthropic official):
- Q1: "site:anthropic.com prompt engineering guide"
- Q2: "site:docs.anthropic.com Claude prompting"

**Round 2** (Structure & Reasoning):
- Q3: "Anthropic XML tags prompt structure"
- Q4: "Claude extended thinking documentation"
- Q5: "chain of thought prompting research 2024"

**Round 3** (System & Security):
- Q6: "Claude system prompt best practices"
- Q7: "prompt injection prevention techniques 2025"
- Q8: "LLM prompt security Anthropic"

**Round 4** (Specialized):
- Q9: "few-shot vs zero-shot when to use LLM"
- Q10: "Constitutional AI prompting safety"
